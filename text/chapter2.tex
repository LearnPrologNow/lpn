

\chapter{Unification and Proof Search}\label{CHAPTER2}

\Thischapter{190}{

\noindent This chapter has two main goals:  
  
\begin{enumerate}

\item{}To discuss unification in Prolog, and to explain how Prolog
  unification differs from standard unification.  Along the way, we'll
  introduce \texttt{=/2}, the built-in predicate for Prolog
  unification, and \texttt{unify\_with\_occurs\_check/2}, the built-in
  predicate for standard unification.
  
\item{}To explain the search strategy Prolog uses when it tries to
  deduce new information from old using modus ponens.

\end{enumerate}

}
\section{Unification}\label{SEC.L2.UNIFICATION}



When working with knowledge base KB4 in the previous chapter, we
briefly mentioned the idea of \LPNterm{unification}. We said, for
example, that Prolog unifies §woman(X)§ with §woman(mia)§, thereby
\LPNterm{instantiating} the variable §X§ to §mia§. It's now time to take a
closer look at unification, for it is one of the most fundamental
ideas in Prolog.

Recall that there are three types of term:  
  
\begin{enumerate}
\item{}Constants. These can either be atoms (such as §vincent§) or numbers   
(such as §24§).
\item{}Variables. (Such as §X§, §Z3§, and §List§.)
\item{}Complex terms. These have the form:\\ §functor(term_1,...,term_n)§.
\end{enumerate}

We are  going to work our way towards a  definition of when
Prolog will unify two terms.  Our starting point will be the following
working definition. It gives the basic intuition, but is a little
light on detail:
%
\begin{center}\parbox{0.9\textwidth}{
    \LPNemph{Two terms unify if they are the same term or if they
    contain variables that can be uniformly instantiated with terms in
    such a way that the resulting terms are equal.}  
}
\end{center}  
%
This means, for example, that the terms §mia§ and §mia§ unify, because
they are the same atom. Similarly, the terms §42§ and §42§ unify,
because they are the same number, the terms §X§ and §X§ unify, because
they are the same variable, and the terms §woman(mia)§ and
§woman(mia)§ unify, because they are the same complex term. The terms
§woman(mia)§ and §woman(vincent)§, however, do not unify, as they are
not the same (and neither of them contains a variable that could be
instantiated to make them the same).

Now, what about the terms §mia§ and §X§? They are not the same.
However, the variable §X§ can be instantiated to §mia§ which makes
them equal. So, by the second part of our working definition, §mia§
and §X§ unify. Similarly, the terms §woman(X)§ and §woman(mia)§ unify,
because they can be made equal by instantiating §X§ to §mia§. How
about §loves(vincent,X)§ and §loves(X,mia)§? No. It is impossible to
find an instantiation of §X§ that makes the two terms equal. Do you
see why?  Instantiating §X§ to §vincent§ would give us the terms
§loves(vincent,vincent)§ and §loves(vincent,mia)§, which are obviously
not equal. However, instantiating §X§ to mia, would yield the terms
§loves(vincent,mia)§ and §loves(mia,mia)§, which aren't equal either.

Usually we are not only interested in the fact that two terms unify,
we also want to know how the variables have to be instantiated to make
them equal. And Prolog gives us this information.  When
Prolog unifies two terms it performs all the necessary \LPNterm{instantia\-tions},
so that the terms really are equal afterwards. This functionality,
together with the fact that we are allowed to build complex terms
(that is, \LPNterm{recursively structured} terms) makes unification a
powerful programming mechanism. 

The basic intuitions should now be clear.  Here's the definition which
makes them precise. It tells us not only which terms Prolog will
unify, but also what it will do to the variables to achieve this.
\begin{enumerate}
\item{}\LPNemph{If} §term1§ \LPNemph{and} §term2§ \LPNemph{are constants, then} 
§term1§ \LPNemph{and} §term2§ \LPNemph{unify if and only if they are the same  
atom, or the same number.}
\item{}\LPNemph{If} §term1§ \LPNemph{is a variable and} §term2§
\LPNemph{is any type of term, then} §term1§ \LPNemph{and} §term2§
\LPNemph{unify, and} §term1§ \LPNemph{is instantiated to} §term2§.
\LPNemph{Similarly, if} §term2§ \LPNemph{is a variable and} §term1§
\LPNemph{is any type of term, then} §term1§ \LPNemph{and} §term2§
\LPNemph{unify, and} §term2§ \LPNemph{is instantiated to} §term1§.
\LPNemph{(So if they are both variables, they're both instantiated to
each other, and we say that they \LPNterm{share values}.)}

\item{}\LPNemph{If} §term1§ \LPNemph{and} §term2§ \LPNemph{are complex terms, then   
                they unify if and only if:} 
\begin{enumerate}
\item{}\LPNemph{They have the same functor and arity, and}
\item{}\LPNemph{all their corresponding arguments unify, and}
\item{}\LPNemph{the variable instantiations are compatible. (For example,
it is not possible to instantiate variable} §X§ \LPNemph{to} §mia§
\LPNemph{when unifying one pair of arguments, and to  instantiate}
§X§ \LPNemph{to} §vincent§ \LPNemph{when unifying another pair of
arguments}.)
\end{enumerate}

\item{}\LPNemph{Two terms unify if and only if it follows from the  
previous three clauses that they unify.}
\end{enumerate}
  
Let's have a look at the form of this definition. The first clause
tells us when two constants unify. The second clause tells us when two
terms, one of which is a variable, unify (such terms will always
unify; variables unify with \LPNemph{anything}). Just as importantly,
this clause also tells what instantiations we have to perform to make
the two terms the same. Finally, the third clause tells us when two
complex terms unify.  Note the structure of this definition. Its first
three clauses mirror perfectly the (recursive) structure of terms.


The fourth clause is also important: it says that the first three
clauses tell us all we need to know about the unification of two
terms. If two terms can't be shown to unify using clauses~1--3, then
they \LPNemph{don't} unify. For example, §batman§ does not unify with
§daughter(ink)§. Why not? Well, the first term is a constant, and the
second is a complex term.  But none of the first three clauses tell us
how to unify two such terms, hence (by clause~4) they don't unify.


\subsection*{Examples}\label{SUBSEC.L2.EXAMPLES}


To make sure we've fully understood this definition, let's work
through several examples.  In these examples we'll make use of an
important built-in predicate, the §=/2§ predicate (recall that
writing\index{PROLOG =/2@\texttt{=/2}} §/2§ at the end indicates that
this predicate takes two arguments).


The §=/2§ predicate tests whether its two arguments
unify. For example, if we pose the query
%
\begin{LPNcodedisplay}
?- =(mia,mia).
\end{LPNcodedisplay}
% 
Prolog will respond yes, and if we pose the query  
\begin{LPNcodedisplay}
?- =(mia,vincent).
\end{LPNcodedisplay}
%
Prolog will respond no.

But we usually wouldn't pose these queries in quite this way.  Let's
face it, the notation §=(mia,mia)§ is rather unnatural. It would be
nicer if we could use \LPNterm{infix} notation (that is, if we could
put the §=/2§ functor between its arguments) and write things like:
%
\begin{LPNcodedisplay}
?- mia = mia.
\end{LPNcodedisplay}
In fact, Prolog lets us do this, so in the examples that follow we'll
use infix notation.

Let's return to our first example:
%
\begin{LPNcodedisplay}
?- mia = mia.
yes
\end{LPNcodedisplay}
% 
 
Why does Prolog say yes? This may seem like a silly question: surely
it's obvious that the terms unify! That's true, but how does this
follow from the definition given above? It is important to learn to
think systematically about unification (it is utterly fundamental to
Prolog), and thinking systematically means relating the examples
to the definition of unification given above. So let's think this
example through.

The definition has three clauses. Now, clause~2 is for when one
argument is a variable, and clause~3 is for when both arguments are
complex terms, so these are of no use here. However clause~1 \LPNemph{is}
relevant to our example.  This tells us that two constants unify if
and only if they are exactly the same object. As §mia§ and §mia§
are the same atom, unification succeeds.

A similar argument explains the following responses:  
\begin{LPNcodedisplay}
?- 2 = 2.
yes

?- mia = vincent.
no
\end{LPNcodedisplay}
% 
Once again, clause~1 is relevant here (after all, §2§, §mia§, and
§vincent§ are all constants). And as §2§ is the same number as §2§,
and as §mia§ is \LPNemph{not} the same atom as §vincent§, Prolog
responds yes to the first query and no to the second.

However clause~1 does hold one small surprise for us. Consider the
following query:
\begin{LPNcodedisplay}
?- 'mia' = mia.
yes
\end{LPNcodedisplay}
% 
What's going on here? Why do these two terms unify? Well, as far as
Prolog is concerned, §'mia'§ and §mia§ are the same atom. In fact, for
Prolog, any atom of the form §'symbols'§ is considered the same entity
as the atom of the form §symbols§. This can be a useful feature in
certain kinds of programs, so don't forget it.

On the other hand, to the query  
\begin{LPNcodedisplay}
?- '2' = 2.
\end{LPNcodedisplay}
% 
Prolog will respond no. And if you think about the definitions given
in Chapter~\ref{CHAPTER1}, you will see that this has to be the way
things work.  After all, §2§ is a number, but §'2'§ is an atom. They
simply cannot be the same.

Let's try an example with a variable:  
\begin{LPNcodedisplay}
?- mia = X.

X = mia 
yes
\end{LPNcodedisplay}
% 
Again, this in an easy example: clearly the variable §X§ can be
unified with the constant §mia§, and Prolog does so, and tells us that
it has made this unification. Fine, but how does this follow from our
definition?

The relevant clause here is clause~2. This tells us what happens when
at least one of the arguments is a variable. In our example it is the
second term which is the variable. The definition tells us unification
is possible, and also says that the variable is instantiated to the
first argument, namely §mia§. And this, of course, is exactly what
Prolog does.

Now for an important example: what happens with the following query?  
\begin{LPNcodedisplay}
?- X = Y.
\end{LPNcodedisplay}
% 
Well, depending on your Prolog implementation, you may just get back
the output
\begin{LPNcodedisplay}
?- X = Y.
yes
\end{LPNcodedisplay}
% 
Prolog is simply agreeing that the two terms unify (after all,
variables unify with anything, so they certainly unify with each
other) and making a note that from now on, §X§ and §Y§ denote the same
object, that is, share values.

On the other hand, you may get the following output:  
\begin{LPNcodedisplay}
X = _5071 
Y = _5071
yes
\end{LPNcodedisplay}
What's going on here?  Essentially the same thing. Note that §_5071§
is a variable (recall from Chapter~\ref{CHAPTER1} that strings of
letters and numbers that start with the underscore character are
variables).  Now look at clause~2 of the definition of
unification. This tells us that when two variables are unified, they
share values. So Prolog has created a new variable (namely §_5071§)
and from now on both §X§ and §Y§ share the value of this variable. In
effect, Prolog is creating a common variable name for the two original
variables.  Needless to say, there's nothing magic about the number
§5071§.  Prolog just needs to generate a brand new variable name, and
using numbers is a handy way to do this. It might just as well
generate §_5075§, or §_6189§, or whatever.

Here is another example involving only atoms and variables. How do you
think will Prolog respond?
\begin{LPNcodedisplay}
?- X = mia, X = vincent.
\end{LPNcodedisplay}

 
Prolog will respond no. This query involves two goals, §X = mia§ and
§X = vincent§. Taken separately, Prolog would succeed at both of them,
instantiating §X§ to §mia§ in the first case and to §vincent§ in the
second. And that's exactly the problem here: once Prolog has worked
through the first goal, §X§ is instantiated to (and therefore equal
to) §mia§, so that it simply can't unify with §vincent§ anymore.
Hence the second goal fails. An \LPNemph{instantiated} variable isn't
really a variable anymore: it has become what it was instantiated with.

Now let's look at an example involving complex terms:  
\begin{LPNcodedisplay}
?- k(s(g),Y) = k(X,t(k)).

X = s(g) 
Y = t(k)
yes
\end{LPNcodedisplay}
% 
Clearly the two complex terms unify if the stated variable
instantiations are carried out. But how does this follow from the
definition? Well, first of all, clause~3 has to be used here because
we are trying to unify two complex terms.  So the first thing we need
to do is check that both complex terms have the same functor and
arity. And they do.  Clause~3 also tells us that we have to unify the
corresponding arguments in each complex term. So do the first
arguments, §s(g)§ and §X§, unify? By clause~2, yes, and we instantiate
§X§ to §s(g)§. So do the second arguments, §Y§ and §t(k)§, unify?
Again by clause~2, yes, and we instantiate §Y§ to §t(k)§.

Here's another example with complex terms:  
\begin{LPNcodedisplay}
?- k(s(g), t(k)) = k(X,t(Y)).

X = s(g) 
Y = k 
yes
\end{LPNcodedisplay}
% 
It should be clear that the two terms unify if these instantiations
are carried out. But can you explain, step by step, how this relates
to the definition?

Here is a last example:  
\begin{LPNcodedisplay}
?- loves(X,X) = loves(marcellus,mia).
\end{LPNcodedisplay}
% 
Do these terms unify? No, they don't. It's true that they are both
complex terms and have the same functor and arity, but clause~3 also
demands that all corresponding arguments have to unify, and that the
variable instantiations have to be compatible. This is not the case
here. Unifying the first arguments would instantiate §X§ with
§marcellus§. Unifying the second arguments would instantiate §X§ with
§mia§. Either way, we're blocked.


\subsection*{The occurs check}\label{SUBSEC.L2.OCCURSCHECK}

Unification is a well-known concept, used in several branches of
computer science. It has been thoroughly studied, and many unification
algorithms are known. But Prolog does \textit{not} use a standard
unification algorithm when it performs its version of
unification. Instead it takes a shortcut.  You need to know about this
shortcut.

Consider the following query:  
\begin{LPNcodedisplay}
?- father(X) = X.
\end{LPNcodedisplay}
%  
Do these terms unify or not?  A standard unification algorithm would
say: ``No, they don't''. Why is that? Well, pick any term and instantiate §X§
to the term you picked.  For example, if you instantiate §X§ to
§father(father(butch))§, the left hand side becomes
§father(father(father(butch)))§, and the right hand side becomes
§father(father(butch))§. Obviously these don't unify. Moreover, it
makes no difference what term you instantiate §X§ to.  No matter what
you choose, the two terms cannot possibly be made the same, for the
term on the left will always be one symbol longer than the term on the
right (the functor §father§ on the left will always give it that one
extra level). A standard unification
algorithm will spot this (we'll see why shortly when we discuss the
occurs check), halt, and tell us no.

The recursive definition of Prolog unification given earlier won't do
this. Because the left hand term is the variable \texttt{X}, by
clause~2 it decides that the terms \LPNemph{do} unify, and (in
accordance with clause~2) instantiates \texttt{X} to the right hand
side, namely \texttt{father(X)}. But there's an \texttt{X} in this
term, and \texttt{X} has been instantiated to \texttt{father(X)}, so
Prolog realises that \texttt{father(X)} is really
\texttt{father(father(X))}.  But there's an \texttt{X} here too, and
\texttt{X} has been instantiated to \texttt{father(X)}, so Prolog
realises that \texttt{father(father(X))} is really
\texttt{father(father(father(X)))}, and so on. Having instantiated
\texttt{X} to \texttt{father(X)}, Prolog is committed to carrying out
an unending sequence of expansions.

At least, that's the theory. What happens in practice?  Well, with
older Prolog implementations, what we've just described is exactly
what happens.  You would get a message like:
\begin{LPNcodedisplay}
Not enough memory to complete query!
\end{LPNcodedisplay}
%
and a long string of symbols like:   
\begin{LPNcodedisplay}
X = father(father(father(father(father(father
   (father(father(father(father(father(father
   (father(father(father(father(father(father
   (father(father(father(father(father(father
   (father(father(father(father(father(father
\end{LPNcodedisplay}
Prolog is desperately \LPNemph{trying} to come back with the correctly
instantiated terms, but it can't halt, because the instantiation
process is unbounded. From an abstract mathematical perspective, what
Prolog is trying to do  is sensible. Intuitively, the only way the
two terms could be made to unify would be if §X§ was instantiated to a
term containing an infinitely long string of §father§ functors, so
that the effect of the extra §father§ functor on the left hand side
was cancelled out.  But the terms we compute with are \LPNemph{finite}
entities. Infinite terms are an interesting mathematical abstraction,
but they're not something we can work with.  No matter how hard Prolog
tries, it can never build one. 

Now, it's annoying to have Prolog running out of memory like this, and
sophisticated Prolog implementations have found  ways of coping more
gracefully. Try posing the query §father(X) = X§ to SWI Prolog or
SICStus Prolog. The answer will be something like:
\begin{LPNcodedisplay}
X = father(father(father(father(...))))))))
yes
\end{LPNcodedisplay}
%
That is, these implementations insist that unification \textit{is}
possible, but they \textit{don't} fall into the trap of actually
trying to instantiate a finite term for \texttt{X} as the naive
implementations do. Instead, they detect that there is a potential
problem, halt, declare that unification is possible, and print out a
finite representation of an infinite term, like the
\begin{LPNcodedisplay}
father(father(father(father(...))))))))
\end{LPNcodedisplay}
in the previous query.  Can you compute with these finite
representations of infinite terms?  That depends on the
implementation.  In some systems you cannot do much with them. For
example, posing the query
\begin{LPNcodedisplay}
?- X = father(X), Y = father(Y), X = Y.
\end{LPNcodedisplay} 
would result in a crash (note that the \texttt{X = Y} demands that we
unify two finite representations of infinite terms). Nonetheless, in some
modern systems unification works robustly with such representations
(for example, both SWI and Sicstus can handle the previous example) so you can
actually use them in your programs. However, why you might want to use
such representations, and what such representations actually are, are
topics that lie beyond the scope of this book.


In short, there are actually \textit{three} different responses to the
question ``does \texttt{father(X)} unify with \texttt{X}''. There is
the answer given by the standard unification algorithm (which is to
say no), the response of older Prolog implementations (which is to run
amok until they use up the available memory), and the answer given by
sophisticated Prolog implementations (which is to say yes, and return
a finite representation of an infinite term). In short, there is no
`right' answer to this question. What is important is that you
understand the difference between standard unification and Prolog
unification, and know how the Prolog implementation that \texttt{you}
work with handles such examples.

Now, in the practical session at the end of the chapter we ask you to
try out such examples with your Prolog interpreter. Here we want to
say a little more about the difference between Prolog unification and
standard unification.  Given the very different ways they handle this
example, it may seem that standard unification algorithms and the
Prolog approach to unification are inherently different. Actually,
they're not. There is one simple difference between the two algorithms
that accounts for their different behaviour when faced with the task
of unifying terms like \texttt{X} and \texttt{father(X)}.  A standard
algorithm, when given two terms to unify, first carries out what is
known as the \LPNterm{occurs check}.  This means that if it is asked to
unify a variable with a term, it first checks whether the variable
occurs in the term.  If it does, the standard algorithm declares that
unification is impossible, for  clearly it is the presence of the variable
\texttt{X} in  \texttt{father(X)} which leads to the problems
discussed earlier.  Only if the variable does not occur in the term do
standard algorithms attempt to carry out the unification.


To put it another way, standard unification algorithms are
\LPNemph{pessimistic}.  They first carry out the occurs check, and
only when they are sure that the situation is safe they do go ahead
and actually try to unify the terms. So a standard unification
algorithm will never get locked into a situation where it is endlessly
trying to instantiate variables, or having to appeal to infinite
terms.

Prolog, on the other hand, is \LPNemph{optimistic}. It assumes that
you are not going to give it anything dangerous.  So it takes a
shortcut: it omits the occurs check. As soon as you give it two terms,
it rushes ahead and tries to unify them.  As Prolog is a programming
language, this is an intelligent strategy.  Unification is one of the
fundamental processes that makes Prolog work, so it needs to be
carried out as fast as possible. Carrying out an occurs check every
time unification is called for would slow it down
considerably. Pessimism is safe, but optimism is a lot faster!  Prolog
can only run into problems if you, the programmer, ask it to do
something like unify §X§ with §father(X)§. And it is unlikely you will
ever (intentionally) ask it to do anything like that when writing a
real program.


One final remark.  Prolog comes with a built-in predicate that carries
out standard unification (that is, unification with the occurs
check). The predicate is\index{PROLOG
unify\_with\_occurs\_check/2@\texttt{unify\_with\_occurs\_check/2}}
\begin{LPNcodedisplay}
unify_with_occurs_check/2.
\end{LPNcodedisplay}
So if we posed the query
\begin{LPNcodedisplay}
?- unify_with_occurs_check(father(X),X).
\end{LPNcodedisplay}
we would get the response  no.


\subsection*{Programming with unification}\label{SUBSEC.L2.PROGRAMMING-WITH-UNIFICATION}

As we've said, unification is a fundamental operation in Prolog.  It
plays a key role in Prolog proof search (as we shall soon learn), and
this alone makes it vital. However, as you get to know Prolog better,
it will become clear that unification is interesting and important in its
own right. Indeed, sometimes you can write useful programs simply by
using complex terms to define interesting concepts. Unification can then
be used to pull out the information you want.

Here's a simple example of this, due to Ivan Bratko.%
\footnote{See his book
\textit{Prolog Programing for Artificial Intelligence},
Addison-Wesley Publishing Company, 1990, second edition, pages
41--43.}  
The following two line knowledge base defines two
predicates, namely §vertical/1§ and §horizontal/1§, which specify what
it means for a line to be vertical or horizontal respectively:
%  
\begin{LPNcodedisplay}
vertical(line(point(X,Y),point(X,Z))).

horizontal(line(point(X,Y),point(Z,Y))).    
\end{LPNcodedisplay}


Now, at first glance this knowledge base may seem too simple to be
interesting: it contains just two facts, and no rules.  But wait a
minute: the two facts are expressed using complex terms which again
have complex terms as arguments. Indeed, there are three levels of
terms nested inside terms. Moreover, the deepest level arguments are
all variables, so the concepts are being defined in a general way.
Maybe it's not quite as simple as it seems.  Let's take a closer look.

Right down at the bottom level, we have a complex term with functor
§point§ and two arguments. Its two arguments are intended to be
instantiated to numbers: §point(X,Y)§ represents the Cartesian
coordinates of a point.  That is, the §X§ indicates the horizontal
distance the point is from some fixed point, while the §Y§ indicates
the vertical distance from that same fixed point.

Now, once we've specified two distinct points, we've specified a line,
namely the line between them.  So the two complex terms representing
points are bundled together as the two arguments of another complex
term with the functor §line§. In effect, we represent a line by a
complex term which has two arguments which are complex terms
themselves and represent points. We're using Prolog's ability to build
complex terms to work our way up a hierarchy of concepts.

Being vertical, and being horizontal, are properties of lines. The
predicates §vertical§ and §horizontal§ therefore both take one
argument which represents a line.  The definition of §vertical/1§
simply says: a line that goes between two points that have the same
x-coordinate is vertical.  Note how we capture the effect of ``the same
x-coordinate'' in Prolog: we simply make use of the same variable §X§
as the first argument of the two complex terms representing the
points.

Similarly, the definition of §horizontal/1§ simply says: a line that
goes between two points that have the same y-coordinate is horizontal.
To capture the effect of ``the same y-coordinate'', we use the same
variable §Y§ as the second argument of the two complex terms
representing the points.

What can we do with this knowledge base? Let's look at some examples:  
\begin{LPNcodedisplay}
?- vertical(line(point(1,1),point(1,3))).
yes  
\end{LPNcodedisplay}
% 
This should be clear: the query unifies with the definition of
§vertical/1§ in our little knowledge base (and in particular, the
representations of the two points have the same first argument) so
Prolog says yes.  Similarly we have:
\begin{LPNcodedisplay}
?- vertical(line(point(1,1),point(3,2))).
no  
\end{LPNcodedisplay}
This query does not unify with the definition of §vertical/1§ (the
representations of the two points have different first arguments) so
Prolog says no.

But we can also ask more general questions:  
\begin{LPNcodedisplay}
?- horizontal(line(point(1,1),point(2,Y))).

Y = 1 ;

no
\end{LPNcodedisplay}
% 
Here our query is: if we want a horizontal line between a point at
(1,1), and point whose x-coordinate is 2, what should the y-coordinate
of that second point be?  Prolog correctly tells us that the
y-coordinate should be 1. If we then ask Prolog for a second
possibility (note the §;§) it tells us that no other possibilities
exist.

Now consider the following:  
\begin{LPNcodedisplay}
?- horizontal(line(point(2,3),P)).

P = point(_1972,3) ;

no
\end{LPNcodedisplay}
% 
This query is: if we want a horizontal line between a point at (2,3),
and some other point, what other points are permissible?  The answer
is: any point whose y-coordinate is 3. Note that the §_1972§ in the
first argument of the answer is a variable, which is Prolog's way of
telling us that any x-coordinate at all will do.

A general remark: the answer given to our last query, namely
§point(_1972,3)§, is \LPNemph{structured}. That is, the answer is a
complex term, representing a sophisticated concept (namely ``any point
whose y-coordinate is 3''). This structure was built using unification
and nothing else: no logical inference (and in particular, no use of
modus ponens) was used to produce it.  Building structure by
unification turns out to be a powerful idea in Prolog programming, far
more powerful than this rather simple example might suggest.
Moreover, when a program is written that makes heavy use of
unification, it is likely to be extremely efficient. We will study a
beautiful example in Chapter~\ref{CHAPTER7} when we discuss difference
lists, which are used to implement Prolog's built-in grammar system,
Definite Clause Grammars.

This style of programming is particularly useful in applications where
the important concepts have a natural hierarchical structure (as they
did in the simple knowledge base above), for we can then use complex
terms to represent this structure, and unification to access it.  This
way of working plays an important role in computational linguistics,
for example, because information about language has a natural
hierarchical structure (think of the way sentences can be analysed
into noun phrases and verb phrases, and noun phrases analysed into
determiners and nouns, and so on).



\section{Proof Search}\label{SEC.L2.PROOFSEARCH}
  
Now that we know about unification, we are in a position to learn how
Prolog actually searches a knowledge base to see if a query is
satisfied. That is, we are  ready to learn about \LPNterm{proof
  search}.  We will introduce the basic ideas involved by working
through a simple example.

Suppose we are working with the following knowledge base  
\begin{LPNcodedisplay}
f(a).
f(b).

g(a).
g(b).

h(b).

k(X) :- f(X), g(X), h(X).
\end{LPNcodedisplay}
% 
Suppose we  then pose the query   
\begin{LPNcodedisplay}
?- k(Y).
\end{LPNcodedisplay}
%  
It is probably clear that there is only one answer to this query,
namely §k(b)§, but how exactly does Prolog work this out? Let's see.

Prolog reads the knowledge base, and tries to unify §k(Y)§ with either
a fact, or the head of a rule. It searches the knowledge base top to
bottom, and carries out the unification, if it can, at the first place
possible. Here there is only one possibility: it must unify §k(Y)§ to
the head of the rule §k(X) :- f(X), g(X), h(X)§.

When Prolog unifies the variable in a query to a variable in a fact or
rule, it generates a brand new variable 
(say §_G34§)
to represent the shared 
variables. So the original query now reads:
\begin{LPNcodedisplay}
k(_G34)
\end{LPNcodedisplay}
%
and Prolog knows that  
\begin{LPNcodedisplay}
k(_G34) :- f(_G34), g(_G34), h(_G34).
\end{LPNcodedisplay}


So what do we now have? The original query says: ``I want to find an
individual that has property §k§''. The rule says, ``an individual has
property §k§ if it has properties §f§, §g§, and §h§''. So if Prolog
can find an individual with properties §f§, §g§, and §h§, it will have
satisfied the original query. So Prolog replaces the original query
with the following list of goals:
\begin{LPNcodedisplay}
f(_G34), g(_G34), h(_G34).
\end{LPNcodedisplay}

Our discussion of the querying process so far can be made more elegant
and succinct if we think graphically. Consider the following diagram:
%
\begin{center}
\includegraphics{chap2-pspic1.ps}
\end{center}
% 
Everything in a box is either a query or a goal.  In particular, our
original goal was to prove §k(Y)§, thus this is shown in the top box.
When we unified §k(Y)§ with the head of the rule in the knowledge
base, §X§ §Y§, and the new internal variable §_G34§ were made to share
values, and we were left with the goals §f(_G34),g(_G34),h(_G34)§,
just as shown.

Now, whenever it has a list of goals, Prolog tries to satisfy them one
by one, working through the list in a left to right direction. The
leftmost goal is §f(_G34)§, which reads: ``I want an individual with
property §f§''. Can this goal be satisfied? Prolog tries to do so by
searching through the knowledge base from top to bottom.  The first
item it finds that unifies with this goal is the fact §f(a)§. This
satisfies the goal §f(_G34)§ and we are left with two more goals.
Now, when we unify §f(_G34)§ to §f(a)§, §_G34§ is instantiated to §a§,
and this instantiation applies to all occurrences of §_G34§ in the
list of goals. So the list now looks like this:
\begin{LPNcodedisplay}
g(a),h(a)
\end{LPNcodedisplay}
%  
and our graphical representation of the proof search now looks like this:
%
\begin{center}
\includegraphics{chap2-pspic2.ps}
\end{center}
%

But the fact §g(a)§ is in the knowledge base, so the first goal we  
have to prove is satisfied too. So the goal list becomes 
\begin{LPNcodedisplay}
h(a)
\end{LPNcodedisplay}
%  
and the graphical representation is now
%
\begin{center}
\includegraphics{chap2-pspic3.ps}
\end{center}
%
But there is no way to satisfy §h(a)§, the last remaining goal.  The
only information about §h§ we have in the knowledge base is §h(b)§,
and this won't unify with §h(a)§.

So what happens next? Well, Prolog decides it has made a mistake, and
checks whether it has missed any possible ways of unifying a goal with
a fact or the head of a rule in the knowledge base. It does this by
going back up the path shown in the graphical representation, looking
for alternatives. Now, there is nothing else in the knowledge base
that unifies with §g(a)§, but there \LPNemph{is} another way of
unifying §f(_G34)§.  Points in the search where there are several
alternative ways of unifying a goal against the knowledge base are
called \LPNterm{choice points}.  Prolog keeps track of choice points it
has encountered, so that if it makes a wrong choice it can retreat to
the previous choice point and try something else instead. This process
is called \LPNterm{backtracking}, and it is fundamental to proof search
in Prolog.

So let's carry on with our example. 
Prolog backtracks to the last choice point. This is the
point in the graphical representation where the list of goals was:
\begin{LPNcodedisplay}
f(_G34),g(_G34),h(_G34).
\end{LPNcodedisplay}
Prolog must now redo this work.  First it must try to
\LPNterm{re-satisfy} the first goal  by searching further in the
knowledge base.  It can do this: it sees that it can unify the first
goal with information in the knowledge base by unifying §f(_G34)§ with
§f(b)§. This satisfies the goal §f(_G34)§ and instantiates §X§ to §b§,
so that the remaining goal list is
\begin{LPNcodedisplay}
g(b),h(b).
\end{LPNcodedisplay}
But §g(b)§ is a fact in the knowledge base, so this is satisfied too,
leaving the goal list:
\begin{LPNcodedisplay}
h(b).
\end{LPNcodedisplay}
Moreover, this fact too is in the knowledge base, so this goal is also
satisfied. So Prolog now has an empty list of goals.  This means that
it has now proved everything required to establish the original goal
(that is, §k(Y)§). So the original query \LPNemph{is} satisfiable, and
moreover, Prolog has also discovered what it has to do to satisfy it
(namely instantiate §Y§ to §b§).


It is interesting to consider what happens if we then ask for another
solution by typing:
\begin{LPNcodedisplay}
;
\end{LPNcodedisplay}
This forces Prolog to backtrack to the last choice point, to try and
find another possibility. However, there are no other choice points, as
there are no other possibilities for unifying §h(b)§, §g(b)§,
§f(_G34)§, or §k(Y)§ with clauses in the knowledge base, so Prolog
would respond no.  On the other hand, if there had been other rules
involving §k§, Prolog would have gone off and tried to use them in
exactly the way we have described: that is, by searching top to bottom
in the knowledge base, left to right in goal lists, and backtracking
to the previous choice point whenever it fails.


Let's take a look at the graphical representation of the entire search
process. Some general remarks are called for, for such representations
are an important way of thinking about proof search in Prolog.
%
\begin{center}
\includegraphics{chap2-pspic4.ps}
\end{center}
This diagram has the form of a tree; in fact it is our first example
of what is known as a \LPNterm{search tree}.  The nodes of such trees
say which goals have to be satisfied at the various steps of the proof
search, and the edges keep track of the variable instantiations that
are made when the current goal (that is, the first one in the list of
goals) is unified to a fact or to the head of a rule in the knowledge
base.  Leaf nodes which still contain unsatisfied goals are points
where Prolog failed (either because it made a wrong decision somewhere
along the path, or because no solution exists). Leaf nodes with an
empty goal list correspond to a possible solution.  The edges along
the path from the root node to a successful leaf node tell you the
variable instantiations that need to be made to satisfy the original
query.

Let's have a look at another example. Suppose that we are working with
the following knowledge base:
\begin{LPNcodedisplay}
loves(vincent,mia).
loves(marcellus,mia).

jealous(A,B):- loves(A,C), loves(B,C).
\end{LPNcodedisplay}
%  
Now we pose the query  
\begin{LPNcodedisplay}
?- jealous(X,Y).
\end{LPNcodedisplay}
%  
The search tree for the query looks like this:
%
\begin{center}
\includegraphics{chap2-pspic5.ps}
\end{center}

There is only one possible way of unifying §jealous(X,Y)§ against the
knowledge base, namely by using the rule
\begin{LPNcodedisplay}
jealous(A,B):- loves(A,C), loves(B,C).
\end{LPNcodedisplay}
%  
So the new goals that have to be satisfied are:  
\begin{LPNcodedisplay}
loves(_G5,_G6),loves(_G7,_G6)
\end{LPNcodedisplay}
Now we have to unify §loves(_G5,_G6)§ against the knowledge base.
There are two ways of doing this (it can either be unified with the
first fact or with the second fact) and this is why the path branches
at this point. In both cases the goal §loves(_G7,mia)§ remains, and
this can also be satisfied by using  either of two facts.  All in
all there are four leaf nodes with an empty goal list, which means
that there are four ways of satisfying the original query. The
variable instantiations for each solution can be read off the path
from the root to the leaf node. So the four solutions are:
\begin{enumerate}
\item{}§X = _G5 = vincent§ and   
§Y = _G7 = vincent§
\item{}§X = _G5 = vincent§ and   
§Y = _G7 = marcellus§
\item{}§X = _G5 = marcellus§ and   
§Y = _G7 = vincent§
\item{}§X = _G5 = marcellus§ and   
§Y = _G7 = marcellus§
\end{enumerate}
Work through this example carefully, and make sure you understand it.

%\pagebreak
\section{Exercises}\label{SEC.L2.EXERCISES}

\begin{LPNexercise}{L2.EX1}Which of the following pairs of terms unify?  
Where relevant, give the  
variable instantiations that lead to successful unification.
\begin{enumerate}
\item{}§bread = bread§
\item{}§'Bread' = bread§
\item{}§'bread' = bread§
\item{}§Bread = bread§
\item{}§bread = sausage§
\item{}§food(bread) = bread§
\item{}§food(bread) = X§
\item{}§food(X) = food(bread)§
\item{}§food(bread,X) = food(Y,sausage)§
\item{}§food(bread,X,beer) = food(Y,sausage,X)§
\item{}§food(bread,X,beer) = food(Y,kahuna_burger)§
\item{}§food(X) = X§
\item{}§meal(food(bread),drink(beer)) = meal(X,Y)§
\item{}§meal(food(bread),X) = meal(X,drink(beer))§
\end{enumerate}
\end{LPNexercise}

\begin{LPNexercise}{L2.EX2}We are working with the following knowledge base:  
\begin{LPNcodedisplay}
house_elf(dobby).
witch(hermione).
witch('McGonagall').
witch(rita_skeeter).
magic(X):- house_elf(X).
magic(X):- wizard(X).
magic(X):- witch(X).
\end{LPNcodedisplay}


Which of the following queries are satisfied? Where relevant, give all
the variable instantiations that lead to success.
\begin{enumerate}
\item{}§?- magic(house_elf).§
\item{}§?- wizard(harry).§
\item{}§?- magic(wizard).§
\item{}§?- magic('McGonagall').§
\item{}§?- magic(Hermione).§
\end{enumerate}
Draw the search tree for the query §magic(Hermione)§.
\end{LPNexercise}


\begin{LPNexercise}{L2.EX3}Here is a tiny lexicon
(that is, information about individual words) and a mini grammar
consisting of one syntactic rule (which defines a sentence to be an
entity consisting of five words in the following order: a determiner,
a noun, a verb, a determiner, a noun).
  
\begin{LPNcodedisplay}
word(determiner,a).
word(determiner,every).
word(noun,criminal).
word(noun,'big kahuna burger').
word(verb,eats).
word(verb,likes).

sentence(Word1,Word2,Word3,Word4,Word5):-
   word(determiner,Word1),
   word(noun,Word2),
   word(verb,Word3),
   word(determiner,Word4),
   word(noun,Word5).
\end{LPNcodedisplay}
What query do you have to pose in order to find out which sentences
the grammar can generate?  List all sentences that this grammar can
generate in the order that Prolog will generate them in. 
\end{LPNexercise}



\begin{LPNexercise}{L2.EX4}Here are six Italian words:

\LPNemph{astante}, \LPNemph{astoria}, \LPNemph{baratto},   
\LPNemph{cobalto}, \LPNemph{pistola}, \LPNemph{statale}.

\noindent
They are to be arranged, crossword puzzle   
fashion, in the following grid:  

\bigskip
\begin{center}  
\includegraphics{crosswd2.eps}
\end{center}
\bigskip

The following knowledge base represents a lexicon containing these
words:
\begin{LPNcodedisplay}
word(astante, a,s,t,a,n,t,e).
word(astoria, a,s,t,o,r,i,a).
word(baratto, b,a,r,a,t,t,o).
word(cobalto, c,o,b,a,l,t,o).
word(pistola, p,i,s,t,o,l,a).
word(statale, s,t,a,t,a,l,e).
\end{LPNcodedisplay}
Write a predicate §crossword/6§ that tells us how to fill in the grid.
The first three arguments should be the vertical words from left to
right, and the last three arguments the horizontal words from top
to bottom.\end{LPNexercise}


\section{Practical Session}\label{SEC.L2.PRAXIS}
  
  
By this stage, you should have had your first taste of running Prolog
programs. The purpose of the second practical session is to suggest
two sets of keyboard exercises which will help you get familiar with
the way Prolog works. The first set has to do with unification, the
second with proof search.

First of all, start up your Prolog interpreter. That is, get a screen
displaying the usual ``I'm ready to start'' prompt, which probably looks
something like:
\begin{LPNcodedisplay}
?-
\end{LPNcodedisplay}
Verify your answers to Exercise 2.1, the unification examples. You
don't need to consult any knowledge bases, simply ask Prolog directly
whether it is possible to unify the terms by using the built-in §=/2§
predicate. For example, to test whether §food(bread,X)§ and
§food(Y,sausage)§ unify, just type in
\begin{LPNcodedisplay}
food(bread,X) = food(Y,sausage).
\end{LPNcodedisplay}
%  
and hit return.

You should also look at what happens when your Prolog implementation
attempts to unify terms that can't be unified because it doesn't carry
out an occurs check. For example, see what happens when you give it
the following query:
\begin{LPNcodedisplay}
g(X,Y) = Y.
\end{LPNcodedisplay}
If it handles such examples, try the trickier one mentioned in the
text:
\begin{LPNcodedisplay}
X = f(X), Y = f(Y), X = Y.
\end{LPNcodedisplay} 

Once you've experimented with that, it's time to move on to something
new.  There is another built-in Prolog predicate for
answering queries about unification, namely §\=/2§ (that is: the
2-place predicate §\=§).  \index{PROLOG \=/2@\verb-\=/2-} This works
in the opposite way to the §=/2§ predicate: it succeeds when its two
arguments do \LPNemph{not} unify.  For example, the terms §a§ and §b§
do not unify, which explains the following dialogue:
\begin{LPNcodedisplay}
?- a \= b.
yes
\end{LPNcodedisplay}

Make sure you understand how  §\=/2§ works by trying it
out on (at least) the following examples.  But do this actively, not
passively.  That is, after you type in an example, pause, and try to
work out for yourself what Prolog is going to respond. Only then hit
return to see if you are right.
\begin{enumerate}
\item{}§a \= a§
\item{}§'a' \= a§
\item{}§A \= a§
\item{}§f(a) \= a§
\item{}§f(a) \= A§
\item{}§f(A) \= f(a)§
\item{}§g(a,B,c) \= g(A,b,C)§
\item{}§g(a,b,c) \= g(A,C)§
\item{}§f(X) \= X§
\end{enumerate}
  
Thus the §\=/2§ predicate is (essentially) the negation of
the §=/2§ predicate: a query involving one of these predicates will be
satisfied when the corresponding query involving the other is not, and
vice versa. This is the first example we have seen of a Prolog
mechanism for handling negation.  We discuss Prolog negation (and its
peculiarities) in Chapter~\ref{CHAPTER10}.

It's time to move on and introduce one of the most helpful tools in
Prolog: §trace§.\index{PROLOG trace/0@\texttt{trace/0}} This is a built-in 
Prolog predicate that changes the
way Prolog runs: it forces Prolog to evaluate queries one step at a
time, indicating what it is doing at each step. Prolog waits for you
to press return before it moves to the next step, so that you can see
exactly what is going on. It was really designed to be used as a
debugging tool, but it's also helpful when you're learning
Prolog: stepping through programs using §trace§ is an
\LPNemph{excellent} way of learning how Prolog proof search works.

Let's look at an example.  In the text, we looked at the proof
search involved when we made the query §k(Y)§ to the following
knowledge base:
\begin{LPNcodedisplay}
f(a).
f(b).

g(a).
g(b).

h(b).

k(X):- f(X), g(X), h(X).
\end{LPNcodedisplay}
  
Suppose this knowledge base is in file §proof.pl§. We first consult
it:
\begin{LPNcodedisplay}
?- [proof].
yes
\end{LPNcodedisplay}
%
We then type §trace§, followed by a full stop,  and hit return:  
\begin{LPNcodedisplay}
?- trace.
yes
\end{LPNcodedisplay}
% 
Prolog is now in \LPNterm{trace mode}, and will evaluate all queries step by
step.  For example, if we pose the query §k(X)§, and then hit return
every time Prolog comes back with a §?§, we obtain (something like)
the following:
\begin{LPNcodedisplay}
[trace] 2 ?- k(X).
   Call: (6) k(_G34) ? 
   Call: (7) f(_G34) ? 
   Exit: (7) f(a) ? 
   Call: (7) g(a) ? 
   Exit: (7) g(a) ? 
   Call: (7) h(a) ? 
   Fail: (7) h(a) ? 
   Fail: (7) g(a) ? 
   Redo: (7) f(_G34) ? 
   Exit: (7) f(b) ? 
   Call: (7) g(b) ? 
   Exit: (7) g(b) ? 
   Call: (7) h(b) ? 
   Exit: (7) h(b) ? 
   Exit: (6) k(b) ? 

X = b 
yes
\end{LPNcodedisplay}
  
Study this carefully. That is, try doing the same thing yourself, and
relate this output to the discussion of the example in the text, and
in particular, to the nodes in the search tree.  To get you started,
we'll remark that the third line is where the variable in the query is
(wrongly) instantiated to §a§. The first line marked §fail§ is where
Prolog realises it's taken the wrong path and starts to backtrack, and
the line marked §redo§ is where it tries alternatives for the goal
§f(_G34)§.

\clearpage
While learning Prolog, use trace, and use it heavily. It's a great way
to learn.
Oh yes: you also need to know how to turn trace off. Simply type
notrace\index{PROLOG notrace/0@\texttt{notrace/0}} (followed by a full
stop) and hit return:
\begin{LPNcodedisplay}
?- notrace.
yes
\end{LPNcodedisplay}
